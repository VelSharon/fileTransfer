---
title: "Stat 245 -- Internet Searches"
author: "Sharon Velpula"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    fig_height: 2.2
    fig_width: 4
  pdf_document:
    fig_height: 2.2
    fig_width: 4
  word_document:
    fig_height: 2.2
    fig_width: 4
---

```{r, setup, include = FALSE}
# load packages that are going to be used
require(tidyverse)   # this loads mosaic, ggformula, etc. too
require(ggformula)
require(mosaic)

# Some customization.  You can alter or delete as desired (if you know what you are doing).

theme_set(theme_bw(base_size=12))     # change theme for ggplot2/ggformula

knitr::opts_chunk$set(
  echo = TRUE,      # for homework, always show R code (this is the default)
  tidy = FALSE,     # display code as typed (rather than reformatted)
  size = "small",   # slightly smaller font for code
  message = FALSE, warning = FALSE) # don't print warnings or messages in compiled document. So you MUST check them in RStudio!
```


### Data

The data comes from a paper, The search engine manipulation effect (SEME) and its possible impact on the outcomes of elections by Robert Epstein and Ronald E. Robertson. They report results of experiments designed to measure the effects of biased internet search results on voter opinions.

```{r}
search <-
read_csv('https://sldr.netlify.app/data/election_searches.csv')

glimpse(search) 
```


### Plan 

I am going to fit a model to understand how the number of internet searches someone does per week relates to
demographic information. I have chosen Searches as my response variable and Employment Status, Education as my predictor variables. I am going to fit a negative binomial regression model because Searches, the response variable contains counts. 

### Fit 

```{r}
library(glmmTMB)
search_nb1 <- glmmTMB(Searches ~ Education + Employment_Status, data = search, family = nbinom1(link = 'log'))

search_nb2 <- glmmTMB(Searches ~ Education + Employment_Status, data = search, family = nbinom2(link = 'log'))

AIC(search_nb1, search_nb2)
```


According to this, we can see that search_nb1 model fits better here. 

### Assessement 

## Mean-Var Relationship 

```{r}
library(DHARMa)
nb1_sim <- simulateResiduals(search_nb1)
plotResiduals(nb1_sim)
```
We can see here that the distribution is not uniform and there isn't much of a random spread after 0.1 on the z-axis. The trend line however seems to be aligned quite vertically. Still, this model fails the mean-variance relationship condition because the residuals are not uniformly distributed. 

## Independence of Residuals

```{r}
s245::gf_acf(~(search_nb1))
```

We can see that there is one lag (19) that goes past the bounds and a two more (14 & 32) that are almost past the bounds. However, we can still say that this model passes the independence of residuals condition. 

### Conclusion 

Even though our model seemed to pass the independence of residuals condition, it doesn't have the mean-variance relationship that we expect. Therefore, we can conclude that the model is not accurate to measure how the number of internet searches is affected by education and employment status. 

### Prediction Plot 

## Hypothetical Dataset 

```{r}
hyp_data <- expand.grid(Education = 'Some college or associate degree', Employment_Status = c('Employed', 'Unemployed'))
```

## Make predictions on link scale 
```{r}
search_preds <- predict(search_nb1, newdata = hyp_data, type = 'link', se.fit = TRUE)

glimpse(search_preds)
```

## Compute CIs on link scale, then inverse link transform  
```{r}
hyp_data <- hyp_data |>
mutate(pred = exp(search_preds$fit),
ci_low = exp(search_preds$fit - 1.96*search_preds$se.fit),
ci_up = exp(search_preds$fit + 1.96*search_preds$se.fit))
```

## Prediction Plot
```{r}
gf_point(pred ~ Employment_Status, data = hyp_data) |> 
  gf_errorbar(ci_low + ci_up ~ Employment_Status ) |> 
  gf_labs(y = 'Number of Internet Searches')
```

## Model Selection 
```{r}
require(MuMIn)
search_nb1 <- search_nb1 |> 
  update(na.action = 'na.fail')

search_dredge <- dredge(search_nb1, rank = 'BIC')

search_dredge
```

  